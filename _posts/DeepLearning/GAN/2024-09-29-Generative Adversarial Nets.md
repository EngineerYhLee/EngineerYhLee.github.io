---
published: true
title: "[논문리뷰] Generative Adversarial Nets"
description: "Generative Adversarial Networks (GANs)의 기본 개념과 원리, 그리고 논문에서 제안한 모델의 구조 및 실험 결과에 대한 리뷰입니다."
header:
  teaser: /assets/images/Generative_adversarial_network.png
  og_image: /assets/images/Generative_adversarial_network.png
  image_description: "Generative adversarial network(GAN)"
date: 2024-09-29
last_modified_at: 2024-09-29
toc: true
toc_sticky: true
use_math: true
categories:
  - GAN
tags:
  - DeepLearning
  - GAN
  - GenerativeModel
  - PaperReview
---
## 논문에 대해서
**Generative Adversarial Networks (GANs)**는 2014년 Ian Goodfellow에 의해 처음 제안된 이후, 머신러닝과 딥러닝 분야에서 혁신적인 발전을 이루어냈습니다.
GAN은 데이터 생성의 새로운 방법을 열었을 뿐만 아니라, 이미지 생성, 데이터 증강, 스타일 변환, 텍스트 생성, 의료 이미지 분석 등 다양한 분야에서 실질적인 성과를 보이고 있습니다.

GAN의 중요한 기여는 두 네트워크 간의 적대적 학습(adversarial learning) 구조를 통해 복잡한 데이터 분포를 효과적으로 모델링할 수 있다는 점입니다. 특히, 복잡한 이미지나 영상 데이터를 샘플링할 수 있는 능력은 기존의 생성 모델을 뛰어넘는 성능을 보여주고 있습니다.

GAN이 제안된 이후 수많은 확장 모델들이 등장했으며, Conditional GAN(cGAN), Wasserstein GAN(WGAN), CycleGAN 등은 GAN의 한계를 극복하고 다양한 응용에 적합한 방식으로 발전해 왔습니다. 특히 WGAN은 훈련 불안정성을 해결하기 위해 Wasserstein 거리 개념을 도입했고, CycleGAN은 라벨이 없는 데이터 간의 변환을 가능하게 하여 이미지 변환에 크게 기여했습니다.

해당 포스팅을 작성하는 2024년에도 GAN은 여전히 활발히 연구되고 있으며, 이미지 해상도 개선, 훈련 안정성 및 실제 응용에서의 성능 최적화와 같은 과제가 남아 있지만, GAN 기반 모델의 발전은 자율 주행, 예술 창작, 의료 이미지 생성 등 실생활의 여러 문제를 해결하는 데 필수적인 기술로 자리 잡았습니다.

이 논문을 리뷰하게 된 이유는 바로 이러한 GAN의 영향력 때문입니다. "Generative Adversarial Nets" 논문은 GAN 연구의 출발점이며, 적대적 학습의 개념을 도입한 이 혁신적인 프레임워크가 딥러닝 연구의 패러다임을 바꾼 중요한 작업이기 때문에 다시 한번 되짚어 볼 필요가 있다고 판단했습니다. GAN은 여전히 활발한 연구 주제이자 여러 분야에서 강력한 도구로 자리잡고 있으며, 이 논문이 제안한 기초 아이디어는 앞으로도 많은 연구의 근간이 될 것입니다.

## 논문 정보

- **논문 제목**: Generative Adversarial Nets
- **저자**: Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio
- **소속 기관**: Université de Montréal
- **발표일**: 2014년
- **저널**: NIPS 2014 (Neural Information Processing Systems)
- **논문 링크**: [Generative Adversarial Nets](https://proceedings.neurips.cc/paper_files/paper/2014/hash/5ca3e9b122f61f8f06494c97b1afccf3-Abstract.html){:target="_blank"}

## Abstract(원문 번역)

본 논문에서는 **적대적 과정(adversarial process)**을 통해 생성 모델을 추정하는 새로운 프레임워크를 제안합니다. 두 개의 모델을 동시에 훈련하는 방식으로 이루어지며, 하나는 데이터 분포를 포착하는 **생성 모델 G**, 다른 하나는 샘플이 훈련 데이터에서 온 것인지 G에서 생성된 것인지 구별하는 **판별 모델 D**입니다. G는 D가 오류를 범할 확률을 최대화하는 방향으로 훈련됩니다. 이 프레임워크는 **minimax 2인 게임**과 대응되며, G와 D가 임의의 함수일 때 유일한 해가 존재하며, G는 훈련 데이터 분포를 복구하고 D는 모든 곳에서 1/2이 됩니다. G와 D가 모두 다층 퍼셉트론으로 정의될 경우, 역전파(backpropagation)를 통해 시스템을 훈련할 수 있으며, 훈련 중 또는 샘플 생성 중에 마르코프 체인이나 근사적 추론 네트워크가 필요하지 않습니다. 실험에서는 생성된 샘플의 질적 및 양적 평가를 통해 프레임워크의 가능성을 보여줍니다.

## 1. 개요

**Generative Adversarial Networks (GANs)**는 Ian Goodfellow와 그의 동료들에 의해 2014년에 제안된 새로운 종류의 생성 모델입니다. GAN은 두 개의 모델을 동시에 학습하는 방식으로 작동합니다:
- 하나는 **생성자(Generator)**, 가짜 데이터를 생성하며,
- 다른 하나는 **판별자(Discriminator)**로, 데이터가 진짜인지 가짜인지를 구별하는 역할을 합니다.

이 두 모델은 마치 범죄자와 경찰의 관계처럼 서로 경쟁을 통해 발전하게 됩니다. 생성자는 판별자를 속여 진짜 같은 데이터를 만들려고 시도하고, 판별자는 그 데이터가 진짜인지 가짜인지 구별하려고 합니다. 이 과정에서 두 모델이 상호 발전하여, 결과적으로 생성자가 진짜와 매우 가까운 데이터를 생성하게 됩니다.

## 2. GAN의 기본 구조

GAN은 기본적으로 두 가지 모델로 구성됩니다:

1. **생성자 G**: 랜덤한 입력값을 받아서 가짜 데이터를 생성합니다. 이 가짜 데이터는 실제 데이터와 구분할 수 없을 정도로 진짜와 유사하게 만듭니다.

2. **판별자 D**: 실제 데이터와 생성자가 만든 가짜 데이터를 구별하는 모델입니다. 판별자는 입력받은 데이터가 진짜인지 가짜인지를 예측합니다.

이 두 모델의 학습은 다음과 같은 **minimax 게임** 구조를 따릅니다:

$$ \min_G \max_D V(D, G) = \mathbb{E}_{x \sim p_{data}(x)}[\log D(x)] + \mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z)))] $$

여기서 \( p_{data}(x) \)는 실제 데이터의 분포이고, \( p_z(z) \)는 생성자의 입력값인 노이즈의 분포입니다.

![Generative Adversarial Network]({{ site.url }}{{ site.baseurl }}/assets/images/Generative_adversarial_network.png)

## 3. 학습 과정

GAN의 학습 과정은 두 모델이 번갈아 가며 학습하는 방식으로 이루어집니다. 판별자는 실제 데이터와 가짜 데이터를 정확하게 구분하려고 하고, 생성자는 판별자를 속이기 위해 더욱 정교한 가짜 데이터를 생성합니다.

학습 과정은 다음과 같은 단계를 따릅니다:

1. 판별자는 실제 데이터와 생성된 가짜 데이터를 입력받고, 두 데이터의 차이를 최대화하는 방향으로 학습됩니다.
2. 생성자는 판별자가 자신의 가짜 데이터를 진짜로 판단하도록 속이는 방향으로 학습됩니다.

이러한 과정은 판별자가 더 이상 두 데이터의 차이를 구분하지 못할 때까지 반복됩니다.

## 4. 실험 결과

논문에서는 MNIST, Toronto Face Database(TFD), CIFAR-10 데이터셋을 사용하여 GAN의 성능을 평가하였습니다. GAN은 기존의 생성 모델들과 경쟁력 있는 결과를 보였으며, 특히 MNIST와 같은 간단한 데이터셋에서는 매우 높은 품질의 이미지를 생성하였습니다.

다음은 MNIST와 TFD 데이터셋에서의 결과를 정리한 표입니다:

| Model              | MNIST        | TFD          |
|--------------------|--------------|--------------|
| DBN                | 138 ± 2      | 1909 ± 66    |
| Stacked CAE        | 121 ± 1.6    | 2110 ± 50    |
| Deep GSN           | 214 ± 1.1    | 1890 ± 29    |
| **Adversarial nets**| **225 ± 2**  | **2057 ± 26**|

## 5. 장점과 단점

### 5.1 장점

- **Markov Chain 불필요**: 다른 생성 모델들과 달리, GAN은 Markov Chain을 사용하지 않으며, 이를 통해 더 간단하고 효율적인 학습을 할 수 있습니다.
- **명시적 확률 분포 필요 없음**: GAN은 명시적인 확률 분포를 정의하지 않고도 고품질의 샘플을 생성할 수 있습니다.
- **Sharp한 데이터 생성 가능**: GAN은 매우 선명한 이미지를 생성할 수 있는 능력이 있습니다.

### 5.2 단점

- **학습의 불안정성**: GAN은 학습 과정에서 매우 민감하며, 생성자와 판별자의 학습 균형을 맞추는 것이 어렵습니다. 생성자가 판별자를 너무 쉽게 속이면 학습이 멈추고, 판별자가 너무 강하면 생성자가 발전하지 못합니다.
- **평가의 어려움**: GAN이 생성한 데이터의 품질을 평가하는 것은 어렵습니다. 일반적으로 Parzen window 기반의 log-likelihood 추정 방법을 사용하지만, 이 방법은 높은 차원에서는 성능이 떨어질 수 있습니다.


죄송합니다. 오류를 수정하겠습니다. 다음과 같이 수정된 버전을 제안합니다:

## 6. 결론 및 향후 연구 방향

이 프레임워크는 여러 간단한 확장을 허용합니다:

1. 조건부 생성 모델 $p\(x\|c\)$는 $c$를 G와 D의 입력으로 추가하여 얻을 수 있습니다.
2. 학습된 근사 추론은 보조 네트워크를 훈련하여 $z$를 예측함으로써 수행할 수 있습니다. 이는 wake-sleep 알고리즘의 추론 네트워크와 유사하지만, 생성자 네트워크가 훈련된 후에 고정된 생성자 네트워크에 대해 학습할 수 있다는 장점이 있습니다.
3. 모든 조건부 $p(x_S \| x_{\neg S})$를 대략적으로 모델링할 수 있으며, 이는 매개변수를 공유하는 조건부 모델 패밀리를 훈련하여 가능합니다. 본질적으로, 결정론적 MP-DBM의 확장 버전으로서, GAN을 활용할 수 있습니다.
4. 준지도 학습: 판별자 또는 추론 네트워크에서 얻은 특징은 제한된 라벨 데이터가 있는 경우 분류기의 성능을 향상시킬 수 있습니다.
5. 효율성 개선: G와 D의 동기화를 위한 더 나은 방법을 고안하거나 훈련 중에 샘플링할 $z$의 더 나은 분포를 찾는 연구가 진행될 수 있습니다.

이 논문은 적대적 모델링 프레임워크의 실행 가능성을 입증하였으며, 이러한 연구 방향이 유용할 가능성을 시사합니다.

